{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb08183",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Freemanlabs/giz-rwanda-ai-training/blob/master/intro-to-ai/02_eda/intro_to_eda.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b2828",
   "metadata": {},
   "source": [
    "# Tutorial: Introduction to Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4bee0",
   "metadata": {},
   "source": [
    "This tutorial guides you through the basics of conducting exploratory data analysis (EDA) using Python, from loading data to generating insights through data visualizations.\n",
    "\n",
    "The notebook used in this tutorial examines customer data and showing customers who have left last month and demonstrates how to load, clean, and explore data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd2c06",
   "metadata": {},
   "source": [
    "## What is EDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e23fb",
   "metadata": {},
   "source": [
    "Exploratory data analysis (EDA) is a critical initial step in the data science process that involves analyzing and visualizing data to:\n",
    "\n",
    "- Uncover its main characteristics.\n",
    "- Identify patterns and trends.\n",
    "- Detect anomalies.\n",
    "- Understand relationships between variables.\n",
    "\n",
    "EDA provides insights into the dataset, facilitating informed decisions about further statistical analyses or modeling.\n",
    "\n",
    "This step is very important especially when we arrive at modeling the data in order to apply Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4c345",
   "metadata": {},
   "source": [
    "## Importing the required libraries for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16913b",
   "metadata": {},
   "source": [
    "You start by importing all necessary libraries for data science and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46e4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484a45a",
   "metadata": {},
   "source": [
    "## 1. Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b083e9",
   "metadata": {},
   "source": [
    "Understanding the basics of the dataset is crucial for any data science project. It involves familiarizing oneself with the structure, types, and quality of the data at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee923",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec457e3",
   "metadata": {},
   "source": [
    "Then, you read in the data as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e445ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# df = pd.read_csv(\"data/CustomerChurn.csv\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://raw.githubusercontent.com/Freemanlabs/giz-rwanda-ai-training/master/intro-to-ai/02_eda/data/CustomerChurn.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/site-packages/pandas/io/common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/urllib/request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/urllib/request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/urllib/request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai6/lib/python3.12/urllib/request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"data/CustomerChurn.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Freemanlabs/giz-rwanda-ai-training/master/intro-to-ai/02_eda/data/CustomerChurn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ac000",
   "metadata": {},
   "source": [
    "### Getting Insights About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bc278",
   "metadata": {},
   "source": [
    "- `.shape`: Dimensions\n",
    "- `head()` and `tail()`: Data rows\n",
    "- `.info()`: Data types and nulls\n",
    "- `.dtypes`: Data types\n",
    "- `.describe()`: Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0fe54",
   "metadata": {},
   "source": [
    "The `df.shape` command returns the dimensions of the DataFrame, giving you a quick overview of the number of rows and columns.\n",
    "\n",
    "Let's see the shape of the data using the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2318e",
   "metadata": {},
   "source": [
    "The `df.head()` method shows the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d045ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1d00a",
   "metadata": {},
   "source": [
    "The `df.tail()` method shows the last few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced81bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb5dad",
   "metadata": {},
   "source": [
    "The `df.info()` method lets us see the columns and their data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de04d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concise Summary of the dataframe, as we have too many columns, we are using the verbose = True mode\n",
    "df.info(verbose = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c4d70",
   "metadata": {},
   "source": [
    "The `df.dtypes` command provides the data types of each column, helping you understand the kind of data you are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01bf0b",
   "metadata": {},
   "source": [
    "The `df.describe()` command generates descriptive statistics for numerical columns, such as mean, standard deviation, and percentiles, which can help you identify patterns, detect anomalies, and understand the distribution of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891ea21",
   "metadata": {},
   "source": [
    "`SeniorCitizen` is actually a categorical hence the 25%-50%-75% distribution is not propoer\n",
    "\n",
    "75% customers have tenure less than 55 months\n",
    "\n",
    "Average Monthly charges are USD 64.76 whereas 25% customers pay more than USD 89.85 per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b298fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].value_counts().plot(kind='barh', figsize=(8, 6))\n",
    "plt.xlabel(\"Count\", labelpad=14)\n",
    "plt.ylabel(\"Target Variable\", labelpad=14)\n",
    "plt.title(\"Count of TARGET Variable per category\", y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4efe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df['Churn'].value_counts()/len(df['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc26193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720244a",
   "metadata": {},
   "source": [
    "- Data is highly imbalanced, ratio = 73:27\n",
    "- So we analyse the data with other features while taking the target values separately to get some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325a2a5",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d9add",
   "metadata": {},
   "source": [
    "Cleaning data is a vital step in EDA to ensure the dataset is accurate, consistent, and ready for meaningful analysis. This process involves several key tasks to ensure the data is ready for analysis, including:\n",
    "\n",
    "- Identifying and removing any duplicate data.\n",
    "- Handling missing values, which might involve replacing them with a specific value or removing the affected rows.\n",
    "- Standardizing data types (for example, converting strings to datetime) through conversions and transformations to ensure consistency. You might also want to convert data to a format that's easier for you to work with.\n",
    "\n",
    "This cleaning phase is essential as it improves the quality and reliability of the data, enabling more accurate and insightful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b613b3",
   "metadata": {},
   "source": [
    "### Correcting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1adcd5",
   "metadata": {},
   "source": [
    "Ensure data types are appropriate for analysis. For example, converting:\n",
    "\n",
    "- categorical variables to the correct type\n",
    "- dates to `datetime`\n",
    "- numbers stored as strings to `float/int`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85789c83",
   "metadata": {},
   "source": [
    "`TotalCharges` should be numeric amount. Let's convert it to numerical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data.TotalCharges = pd.to_numeric(telco_data.TotalCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbcd97c",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8d556",
   "metadata": {},
   "source": [
    "Missing values can affect analysis results. Common techniques include filling (`.fillna()`) in missing values or dropping (`.dropna()`) rows/columns.\n",
    "\n",
    "**Filling the Missing Values – Imputation**\n",
    "\n",
    "In this case, we will be filling the missing values with a certain number.\n",
    "\n",
    "The possible ways to do this are:\n",
    "\n",
    "- Filling the missing data with the mean or median value if it’s a numerical variable.\n",
    "- Filling the missing data with mode if it’s a categorical value.\n",
    "- Filling the numerical value with 0 or -999, or some other number that will not occur in the data. This can be done so that the machine can recognize that the data is not real or is different.\n",
    "- Filling the categorical value with a new type for the missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure we do not have missing values\n",
    "telco_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28fe35",
   "metadata": {},
   "source": [
    "Since the % of these records compared to total dataset is very low i.e. 0.15%, it is safe to ignore them from further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing missing values \n",
    "telco_data.dropna(inplace=True)\n",
    "\n",
    "#telco_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93da755",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b2fc7",
   "metadata": {},
   "source": [
    "Check if the data has any duplicate rows or columns. If so, remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc304dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = telco_data.duplicated().sum()\n",
    "\n",
    "# Check for duplicate columns\n",
    "duplicate_columns = telco_data.columns[telco_data.columns.duplicated()].tolist()\n",
    "\n",
    "# Print the duplicates\n",
    "print(\"Duplicate rows count:\", duplicate_rows)\n",
    "print(\"Duplicate columns:\", duplicate_columns)\n",
    "\n",
    "# Drop duplicate rows\n",
    "telco_data = telco_data.drop_duplicates()\n",
    "\n",
    "# Drop duplicate columns\n",
    "telco_data = telco_data.loc[:, ~telco_data.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1f210",
   "metadata": {},
   "source": [
    "### Removing Irrelevant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c30f94",
   "metadata": {},
   "source": [
    "Remove columns not required for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column customerID and tenure\n",
    "telco_data.drop(columns= ['customerID'], axis=1, inplace=True)\n",
    "telco_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93fbd4",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54e9b1",
   "metadata": {},
   "source": [
    "Explore the dataset to gain insights into its structure and distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea06f5d",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efaf25",
   "metadata": {},
   "source": [
    "Analyze individual variables to understand their distribution and characteristics.\n",
    "\n",
    "Plot distibution of individual predictors by churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predictor in enumerate(telco_data.drop(columns=['Churn', 'TotalCharges', 'MonthlyCharges'])):\n",
    "    plt.figure(i)\n",
    "    sns.countplot(data=telco_data, x=predictor, hue='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ae69a",
   "metadata": {},
   "source": [
    "Convert the target variable `Churn` in a binary numeric variable i.e. Yes=1 ; No = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31459cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data['Churn'] = np.where(telco_data.Churn == 'Yes',1,0)\n",
    "telco_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2403d43",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a509fbb",
   "metadata": {},
   "source": [
    "Explore the relationship between two variables to understand their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1_target0=telco_data.loc[telco_data[\"Churn\"]==0]\n",
    "new_df1_target1=telco_data.loc[telco_data[\"Churn\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a27105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniplot(df,col,title,hue =None):\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_context('talk')\n",
    "    plt.rcParams[\"axes.labelsize\"] = 20\n",
    "    plt.rcParams['axes.titlesize'] = 22\n",
    "    plt.rcParams['axes.titlepad'] = 30\n",
    "    \n",
    "    \n",
    "    temp = pd.Series(data = hue)\n",
    "    fig, ax = plt.subplots()\n",
    "    width = len(df[col].unique()) + 7 + 4*len(temp.unique())\n",
    "    fig.set_size_inches(width , 8)\n",
    "    plt.title(title)\n",
    "    ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue) \n",
    "        \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='Partner',title='Distribution of Gender for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d018e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target0,col='Partner',title='Distribution of Gender for Non Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='PaymentMethod',title='Distribution of PaymentMethod for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='Contract',title='Distribution of Contract for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='TechSupport',title='Distribution of TechSupport for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='SeniorCitizen',title='Distribution of SeniorCitizen for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0c0df",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18d772",
   "metadata": {},
   "source": [
    "These are some of the quick insights from this exercise:\n",
    "\n",
    "1. Electronic check medium are the highest churners\n",
    "2. Contract Type - Monthly customers are more likely to churn because of no contract terms, as they are free to go customers.\n",
    "3. No Online security, No Tech Support category are high churners\n",
    "4. Non senior Citizens are high churners\n",
    "\n",
    "Note: There could be many more such insights, so take this as an assignment and try to get more insights :)\n",
    "\n",
    "Exploratory Data Analysis provides valuable insights through data exploration, cleaning, and visualization. By understanding the fundamental steps of EDA and applying them to market analysis, professionals can make data-driven decisions and uncover hidden trends. Mastering EDA techniques is essential for anyone looking to excel in data science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
