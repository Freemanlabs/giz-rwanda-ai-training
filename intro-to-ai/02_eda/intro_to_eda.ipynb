{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb08183",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Freemanlabs/giz-rwanda-ai-training/blob/master/02_eda/intro_to_eda.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b2828",
   "metadata": {},
   "source": [
    "# Tutorial: Introduction to Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4bee0",
   "metadata": {},
   "source": [
    "This tutorial guides you through the basics of conducting exploratory data analysis (EDA) using Python, from loading data to generating insights through data visualizations.\n",
    "\n",
    "The notebook used in this tutorial examines customer data and showing customers who have left last month and demonstrates how to load, clean, and explore data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd2c06",
   "metadata": {},
   "source": [
    "## What is EDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e23fb",
   "metadata": {},
   "source": [
    "Exploratory data analysis (EDA) is a critical initial step in the data science process that involves analyzing and visualizing data to:\n",
    "\n",
    "- Uncover its main characteristics.\n",
    "- Identify patterns and trends.\n",
    "- Detect anomalies.\n",
    "- Understand relationships between variables.\n",
    "\n",
    "EDA provides insights into the dataset, facilitating informed decisions about further statistical analyses or modeling.\n",
    "\n",
    "This step is very important especially when we arrive at modeling the data in order to apply Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4c345",
   "metadata": {},
   "source": [
    "## Importing the required libraries for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16913b",
   "metadata": {},
   "source": [
    "You start by importing all necessary libraries for data science and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46e4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484a45a",
   "metadata": {},
   "source": [
    "## 1. Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b083e9",
   "metadata": {},
   "source": [
    "Understanding the basics of the dataset is crucial for any data science project. It involves familiarizing oneself with the structure, types, and quality of the data at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee923",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec457e3",
   "metadata": {},
   "source": [
    "Then, you read in the data as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e445ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/CustomerChurn.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Freemanlabs/giz-rwanda-ai-training/master/02_eda/data/CustomerChurn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ac000",
   "metadata": {},
   "source": [
    "### Getting Insights About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bc278",
   "metadata": {},
   "source": [
    "- `.shape`: Dimensions\n",
    "- `head()` and `tail()`: Data rows\n",
    "- `.info()`: Data types and nulls\n",
    "- `.dtypes`: Data types\n",
    "- `.describe()`: Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0fe54",
   "metadata": {},
   "source": [
    "The `df.shape` command returns the dimensions of the DataFrame, giving you a quick overview of the number of rows and columns.\n",
    "\n",
    "Let's see the shape of the data using the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2318e",
   "metadata": {},
   "source": [
    "The `df.head()` method shows the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d045ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1d00a",
   "metadata": {},
   "source": [
    "The `df.tail()` method shows the last few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced81bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb5dad",
   "metadata": {},
   "source": [
    "The `df.info()` method lets us see the columns and their data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de04d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concise Summary of the dataframe, as we have too many columns, we are using the verbose = True mode\n",
    "df.info(verbose = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c4d70",
   "metadata": {},
   "source": [
    "The `df.dtypes` command provides the data types of each column, helping you understand the kind of data you are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01bf0b",
   "metadata": {},
   "source": [
    "The `df.describe()` command generates descriptive statistics for numerical columns, such as mean, standard deviation, and percentiles, which can help you identify patterns, detect anomalies, and understand the distribution of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891ea21",
   "metadata": {},
   "source": [
    "`SeniorCitizen` is actually a categorical hence the 25%-50%-75% distribution is not propoer\n",
    "\n",
    "75% customers have tenure less than 55 months\n",
    "\n",
    "Average Monthly charges are USD 64.76 whereas 25% customers pay more than USD 89.85 per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b298fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].value_counts().plot(kind='barh', figsize=(8, 6))\n",
    "plt.xlabel(\"Count\", labelpad=14)\n",
    "plt.ylabel(\"Target Variable\", labelpad=14)\n",
    "plt.title(\"Count of TARGET Variable per category\", y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4efe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df['Churn'].value_counts()/len(df['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc26193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720244a",
   "metadata": {},
   "source": [
    "- Data is highly imbalanced, ratio = 73:27\n",
    "- So we analyse the data with other features while taking the target values separately to get some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325a2a5",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d9add",
   "metadata": {},
   "source": [
    "Cleaning data is a vital step in EDA to ensure the dataset is accurate, consistent, and ready for meaningful analysis. This process involves several key tasks to ensure the data is ready for analysis, including:\n",
    "\n",
    "- Identifying and removing any duplicate data.\n",
    "- Handling missing values, which might involve replacing them with a specific value or removing the affected rows.\n",
    "- Standardizing data types (for example, converting strings to datetime) through conversions and transformations to ensure consistency. You might also want to convert data to a format that's easier for you to work with.\n",
    "\n",
    "This cleaning phase is essential as it improves the quality and reliability of the data, enabling more accurate and insightful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b613b3",
   "metadata": {},
   "source": [
    "### Correcting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1adcd5",
   "metadata": {},
   "source": [
    "Ensure data types are appropriate for analysis. For example, converting:\n",
    "\n",
    "- categorical variables to the correct type\n",
    "- dates to `datetime`\n",
    "- numbers stored as strings to `float/int`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85789c83",
   "metadata": {},
   "source": [
    "`TotalCharges` should be numeric amount. Let's convert it to numerical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data.TotalCharges = pd.to_numeric(telco_data.TotalCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbcd97c",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8d556",
   "metadata": {},
   "source": [
    "Missing values can affect analysis results. Common techniques include filling (`.fillna()`) in missing values or dropping (`.dropna()`) rows/columns.\n",
    "\n",
    "**Filling the Missing Values – Imputation**\n",
    "\n",
    "In this case, we will be filling the missing values with a certain number.\n",
    "\n",
    "The possible ways to do this are:\n",
    "\n",
    "- Filling the missing data with the mean or median value if it’s a numerical variable.\n",
    "- Filling the missing data with mode if it’s a categorical value.\n",
    "- Filling the numerical value with 0 or -999, or some other number that will not occur in the data. This can be done so that the machine can recognize that the data is not real or is different.\n",
    "- Filling the categorical value with a new type for the missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure we do not have missing values\n",
    "telco_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28fe35",
   "metadata": {},
   "source": [
    "Since the % of these records compared to total dataset is very low i.e. 0.15%, it is safe to ignore them from further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing missing values \n",
    "telco_data.dropna(inplace=True)\n",
    "\n",
    "#telco_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93da755",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b2fc7",
   "metadata": {},
   "source": [
    "Check if the data has any duplicate rows or columns. If so, remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc304dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = telco_data.duplicated().sum()\n",
    "\n",
    "# Check for duplicate columns\n",
    "duplicate_columns = telco_data.columns[telco_data.columns.duplicated()].tolist()\n",
    "\n",
    "# Print the duplicates\n",
    "print(\"Duplicate rows count:\", duplicate_rows)\n",
    "print(\"Duplicate columns:\", duplicate_columns)\n",
    "\n",
    "# Drop duplicate rows\n",
    "telco_data = telco_data.drop_duplicates()\n",
    "\n",
    "# Drop duplicate columns\n",
    "telco_data = telco_data.loc[:, ~telco_data.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1f210",
   "metadata": {},
   "source": [
    "### Removing Irrelevant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c30f94",
   "metadata": {},
   "source": [
    "Remove columns not required for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column customerID and tenure\n",
    "telco_data.drop(columns= ['customerID'], axis=1, inplace=True)\n",
    "telco_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93fbd4",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54e9b1",
   "metadata": {},
   "source": [
    "Explore the dataset to gain insights into its structure and distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea06f5d",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efaf25",
   "metadata": {},
   "source": [
    "Analyze individual variables to understand their distribution and characteristics.\n",
    "\n",
    "Plot distibution of individual predictors by churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predictor in enumerate(telco_data.drop(columns=['Churn', 'TotalCharges', 'MonthlyCharges'])):\n",
    "    plt.figure(i)\n",
    "    sns.countplot(data=telco_data, x=predictor, hue='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ae69a",
   "metadata": {},
   "source": [
    "Convert the target variable `Churn` in a binary numeric variable i.e. Yes=1 ; No = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31459cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data['Churn'] = np.where(telco_data.Churn == 'Yes',1,0)\n",
    "telco_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2403d43",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a509fbb",
   "metadata": {},
   "source": [
    "Explore the relationship between two variables to understand their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1_target0=telco_data.loc[telco_data[\"Churn\"]==0]\n",
    "new_df1_target1=telco_data.loc[telco_data[\"Churn\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a27105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniplot(df,col,title,hue =None):\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_context('talk')\n",
    "    plt.rcParams[\"axes.labelsize\"] = 20\n",
    "    plt.rcParams['axes.titlesize'] = 22\n",
    "    plt.rcParams['axes.titlepad'] = 30\n",
    "    \n",
    "    \n",
    "    temp = pd.Series(data = hue)\n",
    "    fig, ax = plt.subplots()\n",
    "    width = len(df[col].unique()) + 7 + 4*len(temp.unique())\n",
    "    fig.set_size_inches(width , 8)\n",
    "    plt.title(title)\n",
    "    ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue) \n",
    "        \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='Partner',title='Distribution of Gender for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d018e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target0,col='Partner',title='Distribution of Gender for Non Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='PaymentMethod',title='Distribution of PaymentMethod for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='Contract',title='Distribution of Contract for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='TechSupport',title='Distribution of TechSupport for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(new_df1_target1,col='SeniorCitizen',title='Distribution of SeniorCitizen for Churned Customers',hue='gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0c0df",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18d772",
   "metadata": {},
   "source": [
    "These are some of the quick insights from this exercise:\n",
    "\n",
    "1. Electronic check medium are the highest churners\n",
    "2. Contract Type - Monthly customers are more likely to churn because of no contract terms, as they are free to go customers.\n",
    "3. No Online security, No Tech Support category are high churners\n",
    "4. Non senior Citizens are high churners\n",
    "\n",
    "Note: There could be many more such insights, so take this as an assignment and try to get more insights :)\n",
    "\n",
    "Exploratory Data Analysis provides valuable insights through data exploration, cleaning, and visualization. By understanding the fundamental steps of EDA and applying them to market analysis, professionals can make data-driven decisions and uncover hidden trends. Mastering EDA techniques is essential for anyone looking to excel in data science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai6-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
